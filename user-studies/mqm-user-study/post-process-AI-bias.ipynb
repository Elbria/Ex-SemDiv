{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a13cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f383e8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230521-173723.json\n",
      "true\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-111906.json\n",
      "true\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: Professional\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230521-194230.json\n",
      "false\n",
      "Critical Hard: 2\n",
      "Critical Easy: 5\n",
      "EN: native\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-164631.json\n",
      "false\n",
      "Critical Hard: 3\n",
      "Critical Easy: 3\n",
      "EN: full\n",
      "PT: Professional\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230521-192517.json\n",
      "false\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-125038.json\n",
      "true\n",
      "Critical Hard: 4\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-171737.json\n",
      "true\n",
      "Critical Hard: 4\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-124444.json\n",
      "false\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: Professional\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230521-191711.json\n",
      "true\n",
      "Critical Hard: 5\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230521-200259.json\n",
      "true\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: Professional\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-131620.json\n",
      "false\n",
      "Critical Hard: 1\n",
      "Critical Easy: 3\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230522-112155.json\n",
      "true\n",
      "Critical Hard: 3\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230525-131226.json\n",
      "true\n",
      "Critical Hard: 4\n",
      "Critical Easy: 5\n",
      "EN: full\n",
      "PT: native\n",
      "\n",
      "\n",
      "responses/ced_gpt/gpt_lit_en_pt_ced_0/20230613-111355.json\n",
      "true\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'r28'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_hl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#print(data['feedback'])\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#print(data['notes28'])\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#continue\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m conf\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr28\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#print(data['with_hl'])\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#print(data['totalTimeInMinutes'])\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_hl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'r28'"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "def extract_numbers(test_string):\n",
    "    test_string = test_string.replace('<h-l-1>', '')\n",
    "    test_string = test_string.replace('</h-l-1>', '')\n",
    "\n",
    "    test_string = test_string.replace('<h-l-2>', '')\n",
    "\n",
    "    test_string = test_string.replace('</h-l-2>', '')\n",
    "\n",
    "    test_string = test_string.replace('<h-l-3>', '')\n",
    "    test_string = test_string.replace('</h-l-3>', '')\n",
    "\n",
    "    numbers = re.findall(r'\\d+', str(test_string))\n",
    "    return numbers\n",
    "\n",
    "batches = ['0', '1']\n",
    "usefuleness, conf, like = [], [], []\n",
    "reliance = []\n",
    "divergence, div_easy, original = [], [],[]\n",
    "divergence_type = []\n",
    "a_ =defaultdict(list)\n",
    "time_without, time_with = [],[]\n",
    "for batch in batches: \n",
    "    for f_name in glob(f'responses/ced_gpt/gpt_lit_en_pt_ced_{batch}/*.json'):\n",
    "        critical_hard_true, critical_hard_false, critical_easy_true, critical_easy_false = 0,0,0,0\n",
    "        print(f_name)\n",
    "        #usefuleness, conf, like = [], [], []\n",
    "        reliance = []\n",
    "        div_easy =[]\n",
    "        divergence, original = [], []\n",
    "        divergence_type = []\n",
    "        time_without, time_with = [],[]\n",
    "        f = open(f_name)\n",
    "        data = json.load(f)\n",
    "        try:\n",
    "            if data['language'] == 'Limited':\n",
    "                continue\n",
    "        except:\n",
    "            a=1\n",
    "        \n",
    "        #try:\n",
    "        #    if data['language_pt'] != 'native\\t' and data['language'] != 'native\\t':\n",
    "        #        continue\n",
    "        #except:\n",
    "        #    a=1\n",
    "\n",
    "        if data['with_hl'] == 'false':\n",
    "            a=1\n",
    "            #continue\n",
    "        print(data['with_hl'])\n",
    "        #print(data['feedback'])\n",
    "        #print(data['notes28'])\n",
    "        #continue\n",
    "\n",
    "        conf.append(float(data['r28']))\n",
    "        #print(data['with_hl'])\n",
    "        #print(data['totalTimeInMinutes'])\n",
    "        if data['with_hl'] == 'false':\n",
    "            time_with.append(data['totalTimeInMinutes'])\n",
    "        else:\n",
    "            time_without.append(data['totalTimeInMinutes'])\n",
    "\n",
    "        #print(data['r28'])\n",
    "        #if data['r28'] != '1':\n",
    "        #    continue\n",
    "        try:\n",
    "            usefuleness.append(float(data['h28']))\n",
    "            #print(data['h28'])\n",
    "        except:\n",
    "            a = 1\n",
    "        #    continue\n",
    "        \n",
    "        try:\n",
    "            if data['with_hl'] == 'true':\n",
    "                like.append(float(data['l28']))\n",
    "        except:\n",
    "            a=1\n",
    "\n",
    "        #divergence, paraphrase, original = [], [],[]\n",
    "        #divergence_type = []\n",
    "        inds = [a for a in data['sample_indices'].split(',')]\n",
    "        for id_, ind_ in enumerate(inds):\n",
    "            ind = str(ind_)\n",
    "            with open(f'static/examples/for_user_study/gpt_lit_en_pt_ced_{batch}/meta_lbl_{ind}.txt', 'r') as meta:\n",
    "                meta = meta.readlines()[0]\n",
    "\n",
    "                try:\n",
    "                    anno = data[f't{id_+1}']\n",
    "                except:\n",
    "                    print('Missing')\n",
    "                    print(meta)\n",
    "                    continue\n",
    "\n",
    "                #print(f'\\nGold: {meta}')\n",
    "                #print(f'Anno: {anno}')\n",
    "                #if data['atncheck1'] != data['class2']:\n",
    "                #    print(data['atncheck1'])\n",
    "                #    print(data['class2'])\n",
    "                #    print('Failed first attention check')\n",
    "                #    continue\n",
    "\n",
    "                #if data['atncheck2'] != data['t7']:\n",
    "                #    print('Failed second attention check')\n",
    "                #    continue\n",
    "                #continue\n",
    "                #if True:\n",
    "                if meta=='ced_gpt':#  anno=='no':\n",
    "                    \n",
    "                    with open(f'static/examples/for_user_study/gpt_lit_en_pt_ced_{batch}/src_{ind}.txt', 'r') as src:\n",
    "                        src = src.readlines()[0]\n",
    "                        src_num = extract_numbers(src)\n",
    "                        #print(f'\\n{src}')\n",
    "\n",
    "                    with open(f'static/examples/for_user_study/gpt_lit_en_pt_ced_{batch}/tgt_{ind}.txt', 'r') as tgt:\n",
    "                        tgt = tgt.readlines()[0]\n",
    "                        tgt_num = extract_numbers(tgt)\n",
    "                        #print(f'\\n{tgt}')\n",
    "                    #print('-'*100)\n",
    "                #print(tgt_num)\n",
    "                \n",
    "                #if set(tgt_num)!=set(src_num):\n",
    "                #    print(src)\n",
    "                #    print(tgt)\n",
    "                #    continue\n",
    "                if meta =='ced_gpt':\n",
    "                    #print(type_)\n",
    "                    #print(src)\n",
    "                    #print(tgt)\n",
    "                    #print('-'*100)\n",
    "                    a=1\n",
    "\n",
    "                #if anno == 'yes' or data[f'class{id_+1}'] !='N/A':\n",
    "                type_ = data[f'class{id_+1}']\n",
    "                if 'Major' in type_:# or 'Minor' in type_:\n",
    "                    anno_corrected = 'yes'\n",
    "                    if data['with_hl'] == 'false': \n",
    "                        if meta == 'ced_gpt':\n",
    "                            critical_hard_false +=1\n",
    "                        elif meta =='ced':\n",
    "                            critical_easy_false +=1\n",
    "                    else:\n",
    "                        if meta == 'ced':\n",
    "                            critical_easy_true +=1\n",
    "                        elif meta =='ced_gpt':\n",
    "                            critical_hard_true +=1 \n",
    "                            \n",
    "                            \n",
    "                elif 'Minor' in type_:\n",
    "                    anno_corrected = 'no'\n",
    "                    if data['with_hl'] == 'false': \n",
    "                        if meta == 'ced':\n",
    "                            critical_easy_false +=1   \n",
    "                    else:\n",
    "                        if meta =='ced':\n",
    "                            critical_easy_true +=1\n",
    "\n",
    "        \n",
    "                else:\n",
    "                    anno_corrected = 'no'\n",
    "                #print(f'{meta}\\t{anno}\\t{type_}')\n",
    "                if meta == 'ced_gpt':# or meta == 'ced':\n",
    "                    #print(f'{meta}\\t{anno}\\t{type_}')\n",
    "                    divergence.append(anno_corrected)\n",
    "                    divergence_type.append(data[f'class{id_+1}'])\n",
    "                elif meta == 'ced':\n",
    "                    #print(f'{meta}\\t{anno}\\t{type_}')\n",
    "                    div_easy.append(anno_corrected)\n",
    "                    #continue\n",
    "                else:\n",
    "                    #print(f'{meta}\\t{anno}\\t{type_}')\n",
    "                    original.append(anno_corrected)\n",
    "\n",
    "                    \n",
    "        d_yes, d = divergence.count('yes'), len(divergence)\n",
    "        #print(f'Critical Hard: {d_yes} out of {d}')\n",
    "        \n",
    "        d_yes, d = div_easy.count('yes'), len(div_easy)\n",
    "        #print(f'Critical Easy: {d_yes} out of {d}')\n",
    "        \n",
    "        o_no, o = original.count('no'), len(original)\n",
    "        #print(f'Original: {o_no} out of {o}')\n",
    "\n",
    "        tp = d_yes\n",
    "        fp = original.count('yes')\n",
    "        fn = divergence.count('no')\n",
    "\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        #f1 = 2*(precision*recall)/(precision+recall)\n",
    "        #over_rel = paraphrase.count('yes')\n",
    "        #app_rel = (original.count('no') + divergence.count('yes'))/ (len(divergence) + len(original))\n",
    "        u = np.mean(usefuleness)\n",
    "        c = np.mean(conf)\n",
    "        l = np.mean(like)\n",
    "\n",
    "        #print(f'Precision: {precision}')\n",
    "        #print(f'Recall: {recall}')\n",
    "        #print(f'F1: {f1}')\n",
    "        #print(f'Ap-reliance: {app_rel}')\n",
    "        #print(f'Over-reliance: {over_rel}')\n",
    "\n",
    "        #print(f'Self-confidence: {c}')\n",
    "        if data['with_hl'] == 'false': \n",
    "            recall = critical_hard_false/5\n",
    "            print(f'Critical Hard: {critical_hard_false}')\n",
    "            print(f'Critical Easy: {critical_easy_false}')\n",
    "        else:\n",
    "            recall = critical_hard_true/5\n",
    "            print(f'Critical Hard: {critical_hard_true}')\n",
    "            print(f'Critical Easy: {critical_easy_true}')\n",
    "            #print(f'Usefuleness: {u}')\n",
    "            #print(f'Like to Use: {l}')\n",
    "        try:\n",
    "            en = data['language']\n",
    "            print(f'EN: {en}')\n",
    "        except:\n",
    "            a =1\n",
    "        pt = data['language_pt']\n",
    "        print(f'PT: {pt}')\n",
    "        print('\\n')\n",
    "        a_[data['with_hl']].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ea9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a_['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b08ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a_['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41894f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a_['false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a_['false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddd6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "batches =['0', '1']\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "divergence, paraphrase, original = [], [],[]\n",
    "divergence_type = []\n",
    "time_without, time_with = [],[]\n",
    "with_, without_, gold_ = defaultdict(list), defaultdict(list),  defaultdict(str)\n",
    "with_type, without_type = defaultdict(list),  defaultdict(list)\n",
    "for batch in batches:\n",
    "    for f_name in glob(f'responses/ced_gpt/gpt_lit_en_pt_ced_{batch}/*.json'):\n",
    "\n",
    "\n",
    "        f = open(f_name)\n",
    "        data = json.load(f)\n",
    "        try:\n",
    "            if data['language'] == 'Limited':\n",
    "                continue\n",
    "        except:\n",
    "            a=1\n",
    "        #if data['with_hl'] == 'false':\n",
    "        #    continue\n",
    "\n",
    "        #print(data['with_hl'])\n",
    "        #print(data['totalTimeInMinutes'])\n",
    "        if data['with_hl'] == 'true':\n",
    "            time_with.append(data['totalTimeInMinutes'])\n",
    "        else:\n",
    "            time_without.append(data['totalTimeInMinutes'])\n",
    "\n",
    "\n",
    "        #try:\n",
    "        #    print(data['h28'])\n",
    "        #except:\n",
    "        #    continue\n",
    "\n",
    "        #divergence, paraphrase, original = [], [],[]\n",
    "        #divergence_type = []\n",
    "        inds = [a for a in data['sample_indices'].split(',')]\n",
    "        for id_, ind_ in enumerate(inds):\n",
    "            ind = str(ind_)\n",
    "            with open(f'static/examples/for_user_study/gpt_lit_en_pt_ced_{batch}/meta_lbl_{ind}.txt', 'r') as meta:\n",
    "                meta = meta.readlines()[0]\n",
    "\n",
    "                try:\n",
    "                    anno = data[f't{id_+1}']\n",
    "                except:\n",
    "                    print('Missing')\n",
    "                    continue\n",
    "\n",
    "                #print(f'\\nGold: {meta}')\n",
    "                #print(f'Anno: {anno}')\n",
    "                #if data['atncheck1'] != data['class2']:\n",
    "                #    print('Failed first attention check')\n",
    "\n",
    "                #if data['atncheck2'] != data['t7']:\n",
    "                #    print('Failed second attention check')\n",
    "\n",
    "                type_ = data[f'class{id_+1}']\n",
    "                if 'Major' in type_:# or 'Minor' in type_:     \n",
    "                    anno_corrected = 'yes'\n",
    "                else:\n",
    "                    anno_corrected = 'no'\n",
    "                #anno_corrected = anno\n",
    "\n",
    "                if meta == 'ced_gpt':\n",
    "                    divergence.append(anno_corrected)\n",
    "                    divergence_type.append(data[f'class{id_+1}'])\n",
    "                else:\n",
    "                    #continue\n",
    "                    original.append(anno_corrected)\n",
    "\n",
    "                if data['with_hl'] == 'true':\n",
    "                    with_[f'{ind}_{batch}_{f_name}'].append(anno_corrected)\n",
    "                    with_type[f'{ind}_{batch}_{f_name}'].append(data[f'class{id_+1}'])\n",
    "                else:\n",
    "                    without_[f'{ind}_{batch}_{f_name}'].append(anno_corrected)\n",
    "                    without_type[f'{ind}_{batch}_{f_name}'].append(data[f'class{id_+1}'])\n",
    "\n",
    "\n",
    "                #print(f'{ind} {meta}')\n",
    "                gold_[f'{ind}_{batch}_{f_name}'] = meta\n",
    "\n",
    "                #if meta == 'chatGPT_paraphrase' and anno=='yes':\n",
    "                #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/src_{ind}.txt', 'r') as src:\n",
    "                #        src = src.readlines()[0]\n",
    "                #        print(f'\\n{src}')\n",
    "\n",
    "                #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/tgt_{ind}.txt', 'r') as tgt:\n",
    "                #        tgt = tgt.readlines()[0]\n",
    "                #        print(f'\\n{tgt}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ee2fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Hard 0.71\n",
      "Without Hard 0.5684210526315789\n",
      "\n",
      "With Easy 0.57\n",
      "Without Easy 0.5473684210526316\n",
      "\n",
      "With ALL 0.64\n",
      "Without ALL 0.5578947368421052\n",
      "\n",
      "WITH\n",
      "Precision: 0.8951048951048951\n",
      "Recall: 0.64\n",
      "F1: 0.7463556851311953\n",
      "\n",
      "WITHOUT\n",
      "Precision: 0.8833333333333333\n",
      "Recall: 0.5578947368421052\n",
      "F1: 0.6838709677419355\n"
     ]
    }
   ],
   "source": [
    "all_, correct = 0  , 0\n",
    "for key, value in with_.items():\n",
    "    if gold_[key] == 'ced_gpt':\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('With Hard ' + str(correct/all_))\n",
    "\n",
    "all_, correct = 0  , 0\n",
    "for key, value in without_.items():\n",
    "    if gold_[key] == 'ced_gpt':\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('Without Hard ' + str(correct/all_))\n",
    "\n",
    "all_, correct = 0  , 0\n",
    "for key, value in with_.items():\n",
    "    if gold_[key] == 'ced':\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('\\nWith Easy ' + str(correct/all_))\n",
    "\n",
    "all_, correct = 0  , 0\n",
    "for key, value in without_.items():\n",
    "    if gold_[key] == 'ced':\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('Without Easy ' + str(correct/all_))\n",
    "\n",
    "all_, correct = 0  , 0\n",
    "for key, value in with_.items():\n",
    "    if gold_[key] == 'ced' or gold_[key] == 'ced_gpt' :\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('\\nWith ALL ' + str(correct/all_))\n",
    "\n",
    "all_, correct = 0  , 0\n",
    "for key, value in without_.items():\n",
    "    if gold_[key] == 'ced'  or gold_[key] == 'ced_gpt' :\n",
    "        all_+=1\n",
    "        if value[0] =='yes':\n",
    "            correct+=1\n",
    "print('Without ALL ' + str(correct/all_))\n",
    "\n",
    "\n",
    "tp, fp, fn = 0, 0, 0\n",
    "for key, value in without_.items():\n",
    "    if gold_[key] == 'ced_gpt' and value[0] == 'yes':\n",
    "        tp +=1\n",
    "    elif gold_[key] == 'ced' and  value[0] == 'yes':\n",
    "        tp +=1\n",
    "            \n",
    "    elif gold_[key] == 'ced_gpt' and  value[0] == 'no':\n",
    "        fn +=1\n",
    "    elif gold_[key] == 'ced' and  value[0] == 'no':\n",
    "        fn +=1\n",
    "            \n",
    "    elif gold_[key] != 'ced_gpt' and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "    elif gold_[key] != 'ced' and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "\n",
    "precision_without = tp/(tp+fp)\n",
    "recall_without = tp/(tp+fn)\n",
    "f1_without = 2*(precision_without*recall_without)/(precision_without+recall_without)\n",
    "    \n",
    "tp, fp, fn = 0, 0, 0\n",
    "for key, value in with_.items():\n",
    "    if gold_[key] == 'ced_gpt' and value[0] == 'yes':\n",
    "        tp +=1\n",
    "    elif gold_[key] == 'ced' and  value[0] == 'yes':\n",
    "        tp +=1\n",
    "            \n",
    "    elif gold_[key] == 'ced_gpt' and  value[0] == 'no':\n",
    "        fn +=1\n",
    "    elif gold_[key] == 'ced' and  value[0] == 'no':\n",
    "        fn +=1\n",
    "            \n",
    "    elif gold_[key] != 'ced_gpt' and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "    elif gold_[key] != 'ced' and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "\n",
    "precision_with = tp/(tp+fp)\n",
    "recall_with = tp/(tp+fn)\n",
    "f1_with = 2*(precision_with*recall_with)/(precision_with+recall_with)\n",
    "\n",
    "print('\\nWITH')\n",
    "print(f'Precision: {precision_with}')\n",
    "print(f'Recall: {recall_with}')\n",
    "print(f'F1: {f1_with}')\n",
    "\n",
    "print('\\nWITHOUT')\n",
    "print(f'Precision: {precision_without}')\n",
    "print(f'Recall: {recall_without}')\n",
    "print(f'F1: {f1_without}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d844ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH\n",
      "Precision: 0.7916666666666666\n",
      "Recall: 0.57\n",
      "F1: 0.6627906976744186\n",
      "\n",
      "WITHOUT\n",
      "Precision: 0.7878787878787878\n",
      "Recall: 0.5473684210526316\n",
      "F1: 0.6459627329192547\n"
     ]
    }
   ],
   "source": [
    "class_ = 'ced'\n",
    "counter_ = 'ced_gpt'\n",
    "tp, fp, fn = 0, 0, 0\n",
    "for key, value in without_.items():\n",
    "    if gold_[key] == counter_:\n",
    "        continue\n",
    "    if gold_[key] == class_ and value[0] == 'yes':\n",
    "        tp +=1\n",
    "    elif gold_[key] == class_ and  value[0] == 'no':\n",
    "        fn +=1            \n",
    "    elif gold_[key] != class_ and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "\n",
    "\n",
    "precision_without = tp/(tp+fp)\n",
    "recall_without = tp/(tp+fn)\n",
    "f1_without = 2*(precision_without*recall_without)/(precision_without+recall_without)\n",
    "    \n",
    "tp, fp, fn = 0, 0, 0\n",
    "for key, value in with_.items():\n",
    "    if gold_[key] == counter_:\n",
    "        continue\n",
    "    if gold_[key] == class_ and value[0] == 'yes':\n",
    "        tp +=1            \n",
    "    elif gold_[key] == class_ and  value[0] == 'no':\n",
    "        fn +=1            \n",
    "    elif gold_[key] != class_ and  value[0] == 'yes':\n",
    "        fp +=1\n",
    "\n",
    "\n",
    "precision_with = tp/(tp+fp)\n",
    "recall_with = tp/(tp+fn)\n",
    "f1_with = 2*(precision_with*recall_with)/(precision_with+recall_with)\n",
    "\n",
    "print('\\nWITH')\n",
    "print(f'Precision: {precision_with}')\n",
    "print(f'Recall: {recall_with}')\n",
    "print(f'F1: {f1_with}')\n",
    "\n",
    "print('\\nWITHOUT')\n",
    "print(f'Precision: {precision_without}')\n",
    "print(f'Recall: {recall_without}')\n",
    "print(f'F1: {f1_without}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8209d447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0171d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.307971428571427\n",
      "13.996577390792092\n",
      "15.535921052631583\n",
      "5.326168606602714\n"
     ]
    }
   ],
   "source": [
    "#np.mean(time_with)\n",
    "print(np.mean([float(a) for a in time_with]))\n",
    "print(np.std([float(a) for a in time_with]))\n",
    "print(np.mean([float(a) for a in time_without]))\n",
    "print(np.std([float(a) for a in time_without]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978e6738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n",
      "Missing\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "batches =['0','1']\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "divergence, paraphrase, original = [], [],[]\n",
    "divergence_type = []\n",
    "time_without, time_with = [],[]\n",
    "with_, without_, gold_ = defaultdict(list), defaultdict(list),  defaultdict(str)\n",
    "with_type, without_type = defaultdict(list),  defaultdict(list)\n",
    "for batch in batches:\n",
    "    for f_name in glob(f'responses/ced_gpt/gpt_lit_en_pt_ced_{batch}/*.json'):\n",
    "\n",
    "\n",
    "        f = open(f_name)\n",
    "        data = json.load(f)\n",
    "        try:\n",
    "            if data['language'] == 'Limited':# or data['language'] == 'native':\n",
    "                continue\n",
    "        except:\n",
    "            a=1\n",
    "        #if data['with_hl'] == 'false':\n",
    "        #    continue\n",
    "\n",
    "        #print(data['with_hl'])\n",
    "        #print(data['totalTimeInMinutes'])\n",
    "        if data['with_hl'] == 'true':\n",
    "            time_with.append(data['totalTimeInMinutes'])\n",
    "        else:\n",
    "            time_without.append(data['totalTimeInMinutes'])\n",
    "\n",
    "\n",
    "        #try:\n",
    "        #    print(data['h28'])\n",
    "        #except:\n",
    "        #    continue\n",
    "\n",
    "        #divergence, paraphrase, original = [], [],[]\n",
    "        #divergence_type = []\n",
    "        inds = [a for a in data['sample_indices'].split(',')]\n",
    "        for id_, ind_ in enumerate(inds):\n",
    "            ind = str(ind_)\n",
    "            with open(f'static/examples/for_user_study/gpt_lit_en_pt_ced_{batch}/meta_lbl_{ind}.txt', 'r') as meta:\n",
    "                meta = meta.readlines()[0]\n",
    "\n",
    "                try:\n",
    "                    anno = data[f't{id_+1}']\n",
    "                except:\n",
    "                    print('Missing')\n",
    "                    continue\n",
    "\n",
    "                #print(f'\\nGold: {meta}')\n",
    "                #print(f'Anno: {anno}')\n",
    "                #if data['atncheck1'] != data['class2']:\n",
    "                #    print('Failed first attention check')\n",
    "\n",
    "                #if data['atncheck2'] != data['t7']:\n",
    "                #    print('Failed second attention check')\n",
    "\n",
    "                type_ = data[f'class{id_+1}']\n",
    "                if 'Major' in type_:# or 'Minor' in type_:     \n",
    "                    anno_corrected = 'yes'\n",
    "                else:\n",
    "                    anno_corrected = 'no'\n",
    "                #anno_corrected = anno\n",
    "\n",
    "                if meta == 'ced_gpt':\n",
    "                    divergence.append(anno_corrected)\n",
    "                    divergence_type.append(data[f'class{id_+1}'])\n",
    "                else:\n",
    "                    #continue\n",
    "                    original.append(anno_corrected)\n",
    "\n",
    "                if data['with_hl'] == 'true':\n",
    "                    with_[f'{ind}_{batch}'].append(anno_corrected)\n",
    "                    with_type[f'{ind}_{batch}'].append(data[f'class{id_+1}'])\n",
    "                else:\n",
    "                    without_[f'{ind}_{batch}'].append(anno_corrected)\n",
    "                    without_type[f'{ind}_{batch}'].append(data[f'class{id_+1}'])\n",
    "\n",
    "\n",
    "                #print(f'{ind} {meta}')\n",
    "                gold_[f'{ind}_{batch}'] = meta\n",
    "\n",
    "                #if meta == 'chatGPT_paraphrase' and anno=='yes':\n",
    "                #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/src_{ind}.txt', 'r') as src:\n",
    "                #        src = src.readlines()[0]\n",
    "                #        print(f'\\n{src}')\n",
    "\n",
    "                #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/tgt_{ind}.txt', 'r') as tgt:\n",
    "                #        tgt = tgt.readlines()[0]\n",
    "                #        print(f'\\n{tgt}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f75a32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'21_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '11_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '2_0': ['yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no'],\n",
       "             '13_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '1_0': ['yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '22_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '15_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '4_0': ['yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no'],\n",
       "             '12_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '19_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '23_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '16_0': ['yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no'],\n",
       "             '8_0': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '7_0': ['no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '9_0': ['no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '5_0': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '18_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '25_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '24_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '6_0': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '20_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '3_0': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '17_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no'],\n",
       "             '14_0': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '10_0': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '21_1': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'],\n",
       "             '10_1': ['no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '19_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '12_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '18_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '1_1': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '6_1': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '24_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '25_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '13_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '9_1': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no'],\n",
       "             '14_1': ['yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '20_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '15_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '2_1': ['no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '7_1': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes'],\n",
       "             '22_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '3_1': ['no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '17_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '11_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '5_1': ['no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'yes'],\n",
       "             '16_1': ['no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '23_1': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'],\n",
       "             '8_1': ['no',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'yes',\n",
       "              'no',\n",
       "              'no'],\n",
       "             '4_1': ['yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes',\n",
       "              'yes']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11db3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777441262974514\n",
      "0.11039641965631809\n",
      "0.44058012410020964\n",
      "0.12178041525462065\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "k = []\n",
    "for i in range(25):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in with_.values():\n",
    "        #print(annos)\n",
    "        [l1, l2] = random.sample(annos, 2)\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "\n",
    "k = []\n",
    "for i in range(25):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in without_.values():\n",
    "        [l1, l2] = random.sample(annos, 2)\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed0404ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "with_flattened = defaultdict(str)\n",
    "for key, value in with_.items():\n",
    "    with_flattened[f'{key}_a'] = value[0]\n",
    "    with_flattened[f'{key}_b'] = value[1]\n",
    "    with_flattened[f'{key}_c'] = value[2]\n",
    "    with_flattened[f'{key}_d'] = value[3]\n",
    "    with_flattened[f'{key}_e'] = value[4]\n",
    "\n",
    "\n",
    "        \n",
    "without_flattened = defaultdict(str)\n",
    "for key, value in without_.items():\n",
    "    without_flattened[f'{key}_a'] = value[0]\n",
    "    without_flattened[f'{key}_b'] = value[1]\n",
    "    without_flattened[f'{key}_c'] = value[2]\n",
    "    without_flattened[f'{key}_d'] = value[3]\n",
    "    without_flattened[f'{key}_e'] = value[4]\n",
    "        \n",
    "print(len(with_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dc9576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'21_0': 'original',\n",
       "             '11_0': 'original',\n",
       "             '2_0': 'ced',\n",
       "             '13_0': 'original',\n",
       "             '1_0': 'ced',\n",
       "             '22_0': 'original',\n",
       "             '15_0': 'original',\n",
       "             '4_0': 'ced',\n",
       "             '12_0': 'original',\n",
       "             '19_0': 'original',\n",
       "             '23_0': 'original',\n",
       "             '16_0': 'original',\n",
       "             '8_0': 'ced_gpt',\n",
       "             '7_0': 'ced_gpt',\n",
       "             '9_0': 'ced_gpt',\n",
       "             '5_0': 'ced',\n",
       "             '18_0': 'original',\n",
       "             '25_0': 'original',\n",
       "             '24_0': 'original',\n",
       "             '6_0': 'ced_gpt',\n",
       "             '20_0': 'original',\n",
       "             '3_0': 'ced',\n",
       "             '17_0': 'original',\n",
       "             '14_0': 'original',\n",
       "             '10_0': 'ced_gpt',\n",
       "             '3_1': 'ced',\n",
       "             '13_1': 'original',\n",
       "             '8_1': 'ced_gpt',\n",
       "             '6_1': 'ced_gpt',\n",
       "             '25_1': 'original',\n",
       "             '15_1': 'original',\n",
       "             '9_1': 'ced_gpt',\n",
       "             '5_1': 'ced',\n",
       "             '23_1': 'original',\n",
       "             '16_1': 'original',\n",
       "             '10_1': 'ced_gpt',\n",
       "             '19_1': 'original',\n",
       "             '11_1': 'original',\n",
       "             '1_1': 'ced',\n",
       "             '20_1': 'original',\n",
       "             '17_1': 'original',\n",
       "             '12_1': 'original',\n",
       "             '2_1': 'ced',\n",
       "             '7_1': 'ced_gpt',\n",
       "             '22_1': 'original',\n",
       "             '4_1': 'ced',\n",
       "             '21_1': 'original',\n",
       "             '14_1': 'original',\n",
       "             '18_1': 'original',\n",
       "             '24_1': 'original',\n",
       "             '13': '',\n",
       "             '5': '',\n",
       "             '12': '',\n",
       "             '14': '',\n",
       "             '24': '',\n",
       "             '21': '',\n",
       "             '8': '',\n",
       "             '22': '',\n",
       "             '9': '',\n",
       "             '19': '',\n",
       "             '25': '',\n",
       "             '18': '',\n",
       "             '17': '',\n",
       "             '6': '',\n",
       "             '11': '',\n",
       "             '10': '',\n",
       "             '2': '',\n",
       "             '3': '',\n",
       "             '4': '',\n",
       "             '15': '',\n",
       "             '7': '',\n",
       "             '20': '',\n",
       "             '16': '',\n",
       "             '23': '',\n",
       "             '1': ''})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ad7b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4289\n",
      "0.2788\n",
      "0.2886\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1_ = [], [],[]\n",
    "samples = 10000\n",
    "exlcude_easy = True\n",
    "subsample_size = 250\n",
    "p_pr, p_re, p_f1 = 0, 0, 0\n",
    "for i in range(samples):\n",
    "\n",
    "    subsample = []\n",
    "    for j in range(subsample_size):\n",
    "        subsample.append(random.sample(list(with_flattened.keys()), 1)[0])\n",
    "    \n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for key in subsample:\n",
    "        sampled = with_flattened[key]\n",
    "        key_ = '_'.join(key.split('_')[:2])\n",
    "        if gold_[key_] == 'ced' and exlcude_easy:\n",
    "            continue\n",
    "   \n",
    "        if gold_[key_] == 'ced_gpt' and sampled == 'yes':\n",
    "            tp +=1\n",
    "        elif gold_[key_] == 'ced' and sampled == 'yes':\n",
    "            tp +=1\n",
    "            \n",
    "        elif gold_[key_] == 'ced_gpt' and sampled == 'no':\n",
    "            fn +=1\n",
    "        elif gold_[key_] == 'ced' and sampled == 'no':\n",
    "            fn +=1\n",
    "            \n",
    "        elif gold_[key_] != 'ced_gpt' and sampled == 'yes':\n",
    "            fp +=1\n",
    "        elif gold_[key_] != 'ced' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "    #print(tp)\n",
    "    #print(fp)\n",
    "    #print(fn)\n",
    "    precision_with = tp/(tp+fp)\n",
    "    recall_with = tp/(tp+fn)\n",
    "    f1_with = 2*(precision_with*recall_with)/(precision_with+recall_with)\n",
    "\n",
    "    #pr.append(precision)\n",
    "    #re.append(recall)\n",
    "    #f1_.append(f1)\n",
    "    \n",
    "    subsample = []\n",
    "    for j in range(subsample_size):\n",
    "        subsample.append(random.sample(list(without_flattened.keys()), 1)[0])\n",
    "    \n",
    "    \n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for key in subsample:\n",
    "        sampled = without_flattened[key]\n",
    "        key_ = '_'.join(key.split('_')[:2])\n",
    "        if gold_[key_] == 'ced' and exlcude_easy:\n",
    "            continue\n",
    "   \n",
    "        if gold_[key_] == 'ced_gpt' and sampled == 'yes':\n",
    "            tp +=1\n",
    "        elif gold_[key_] == 'ced' and sampled == 'yes':\n",
    "            tp +=1\n",
    "            \n",
    "        elif gold_[key_] == 'ced_gpt' and sampled == 'no':\n",
    "            fn +=1\n",
    "        elif gold_[key_] == 'ced' and sampled == 'no':\n",
    "            fn +=1\n",
    "            \n",
    "        elif gold_[key_] != 'ced_gpt' and sampled == 'yes':\n",
    "            fp +=1\n",
    "        elif gold_[key_] != 'ced' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_without = tp/(tp+fp)\n",
    "    recall_without = tp/(tp+fn)\n",
    "    f1_without = 2*(precision_without*recall_without)/(precision_without+recall_without)\n",
    "    \n",
    "    if recall_with < recall_without:\n",
    "        p_re+=1\n",
    "    #print(f'{precision_with}\\t{precision_without}')\n",
    "    if precision_with < precision_without:\n",
    "        p_pr+=1\n",
    "    if f1_with < f1_without:\n",
    "        p_f1+=1\n",
    "\n",
    "print(p_pr/samples)\n",
    "print(p_re/samples)\n",
    "print(p_f1/samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3f56ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4304\n",
      "0.2108\n",
      "0.2693\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1_ = [], [],[]\n",
    "samples = 10000\n",
    "exlcude_easy = False\n",
    "p_pr, p_re, p_f1 = 0, 0, 0\n",
    "for i in range(samples):\n",
    "\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for key, value in with_.items():\n",
    "        if gold_[key] == 'ced' and exlcude_easy:\n",
    "            continue\n",
    "   \n",
    "        sampled = random.sample(value, 1)[0]\n",
    "        if gold_[key] == 'ced_gpt' and sampled == 'yes':\n",
    "            tp +=1\n",
    "        elif gold_[key] == 'ced' and sampled == 'yes':\n",
    "            tp +=1\n",
    "            \n",
    "        elif gold_[key] == 'ced_gpt' and sampled == 'no':\n",
    "            fn +=1\n",
    "        elif gold_[key] == 'ced' and sampled == 'no':\n",
    "            fn +=1\n",
    "            \n",
    "        elif gold_[key] != 'ced_gpt' and sampled == 'yes':\n",
    "            fp +=1\n",
    "        elif gold_[key] != 'ced' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "    #print(tp)\n",
    "    #print(fp)\n",
    "    #print(fn)\n",
    "    precision_with = tp/(tp+fp)\n",
    "    recall_with = tp/(tp+fn)\n",
    "    f1_with = 2*(precision_with*recall_with)/(precision_with+recall_with)\n",
    "\n",
    "    #pr.append(precision)\n",
    "    #re.append(recall)\n",
    "    #f1_.append(f1)\n",
    "    \n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for key, value in without_.items():\n",
    "        if gold_[key] == 'ced' and exlcude_easy:\n",
    "            continue\n",
    "\n",
    "        sampled = random.sample(value, 1)[0]\n",
    "        if gold_[key] == 'ced_gpt' and sampled == 'yes':\n",
    "            tp +=1\n",
    "        elif gold_[key] == 'ced' and sampled == 'yes':\n",
    "            tp +=1\n",
    "            \n",
    "        elif gold_[key] == 'ced_gpt' and sampled == 'no':\n",
    "            fn +=1\n",
    "        elif gold_[key] == 'ced' and sampled == 'no':\n",
    "            fn +=1\n",
    "            \n",
    "        elif gold_[key] != 'ced_gpt' and sampled == 'yes':\n",
    "            fp +=1\n",
    "        elif gold_[key] != 'ced' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_without = tp/(tp+fp)\n",
    "    recall_without = tp/(tp+fn)\n",
    "    f1_without = 2*(precision_without*recall_without)/(precision_without+recall_without)\n",
    "    \n",
    "    if recall_with < recall_without:\n",
    "        p_re+=1\n",
    "    #print(f'{precision_with}\\t{precision_without}')\n",
    "    if precision_with < precision_without:\n",
    "        p_pr+=1\n",
    "    if f1_with < f1_without:\n",
    "        p_f1+=1\n",
    "\n",
    "print(p_pr/samples)\n",
    "print(p_re/samples)\n",
    "print(p_f1/samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b12f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num\n",
    "\n",
    "tp, fn, fp = 0, 0, 0\n",
    "for key, value in without_.items():\n",
    "    \n",
    "    if gold_[key] == 'ced_gpt' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    elif gold_[key] == 'ced' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    \n",
    "    elif gold_[key] == 'ced_gpt' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "    elif gold_[key] == 'ced' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "        \n",
    "    elif gold_[key] != 'ced_gpt' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "    elif gold_[key] != 'ced' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "        \n",
    "    #print(gold_[key])\n",
    "    #print(most_frequent(value))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fn, fp = 0, 0, 0\n",
    "for key, value in with_.items():\n",
    "    \n",
    "    if gold_[key] == 'ced_gpt' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    elif gold_[key] == 'ced' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    \n",
    "    elif gold_[key] == 'ced_gpt' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "    elif gold_[key] == 'ced' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "        \n",
    "    elif gold_[key] != 'ced_gpt' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "    elif gold_[key] != 'ced' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "        \n",
    "    #print(gold_[key])\n",
    "    #print(most_frequent(value))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in range(100):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in with_type.values():\n",
    "        #if len(set(annos))==1 and annos[0]=='N/A':\n",
    "        #    continue\n",
    "        #annos = [a for a in annos if a!='N/A']\n",
    "        try:\n",
    "            [l1, l2] = random.sample(annos, 2)\n",
    "        except:\n",
    "            continue\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "\n",
    "k = []\n",
    "for i in range(100):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in without_type.values():\n",
    "        #if len(set(annos))==1 and annos[0]=='N/A':\n",
    "        #    continue\n",
    "        #annos = [a for a in annos if a!='N/A']\n",
    "        try:\n",
    "            [l1, l2] = random.sample(annos, 2)\n",
    "        except:\n",
    "            continue\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(usefuleness, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(like, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0409d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 5.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefuleness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623ada11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5f3504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3b64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb97657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
