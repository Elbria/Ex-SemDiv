{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a13cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f383e8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "Recall: 0.8\n",
      "true\n",
      "Missing\n",
      "Recall: 0.7777777777777778\n",
      "false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.0\n",
      "false\n",
      "Recall: 0.75\n",
      "true\n",
      "Recall: 0.9\n",
      "false\n",
      "Recall: 0.75\n",
      "false\n",
      "Recall: 0.875\n",
      "true\n",
      "Recall: 0.8\n",
      "false\n",
      "Recall: 1.0\n",
      "true\n",
      "Recall: 0.9\n",
      "true\n",
      "Recall: 1.0\n",
      "false\n",
      "Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "lang = 'fr'\n",
    "\n",
    "a_ = defaultdict(list)\n",
    "usefuleness, conf = [], []\n",
    "reliance = []\n",
    "divergence, paraphrase, original = [], [],[]\n",
    "divergence_type = []\n",
    "time_without, time_with = [],[]\n",
    "for f_name in glob(f'responses/{lang}/*.json'):\n",
    "    if f_name == f'responses/{lang}/marine.json':# or f_name == 'responses/fr/20230420-134831.json':\n",
    "        continue\n",
    "    #print(f_name)\n",
    "    \n",
    "    usefuleness, conf = [], []\n",
    "    reliance = []\n",
    "    divergence, paraphrase, original = [], [],[]\n",
    "    divergence_type = []\n",
    "    time_without, time_with = [],[]\n",
    "    \n",
    "    f = open(f_name)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    if data['with_hl'] == 'false':\n",
    "        print('false')\n",
    "    else:\n",
    "        print('true')\n",
    "        \n",
    "        #continue\n",
    "    #print(data['feedback'])\n",
    "    #print(data['notes28'])\n",
    "\n",
    "\n",
    "    conf.append(float(data['r28']))\n",
    "    #print(data['with_hl'])\n",
    "    #print(data['totalTimeInMinutes'])\n",
    "    if data['with_hl'] == 'false':\n",
    "        time_with.append(data['totalTimeInMinutes'])\n",
    "    else:\n",
    "        time_without.append(data['totalTimeInMinutes'])\n",
    "\n",
    "    #if data['r28'] != '1':\n",
    "    #    continue\n",
    "    try:\n",
    "        usefuleness.append(float(data['h28']))\n",
    "        #print(data['h28'])\n",
    "    except:\n",
    "        a = 1\n",
    "    #    continue\n",
    "\n",
    "    #divergence, paraphrase, original = [], [],[]\n",
    "    #divergence_type = []\n",
    "    inds = [a for a in data['sample_indices'].split(',')]\n",
    "    for id_, ind_ in enumerate(inds):\n",
    "        ind = str(ind_)\n",
    "        with open(f'static/examples/for_user_study/flores_gpt_paraphrase_{lang}/meta_lbl_{ind}.txt', 'r') as meta:\n",
    "            meta = meta.readlines()[0]\n",
    "\n",
    "            try:\n",
    "                anno = data[f't{id_+1}']\n",
    "            except:\n",
    "                print('Missing')\n",
    "                continue\n",
    "\n",
    "            #print(f'\\nGold: {meta}')\n",
    "            #print(f'Anno: {anno}')\n",
    "            #if data['atncheck1'] != data['class2']:\n",
    "            #    print('Failed first attention check')\n",
    "            #    continue\n",
    "\n",
    "            #if data['atncheck2'] != data['t7']:\n",
    "            #    print('Failed second attention check')\n",
    "            #    continue\n",
    "                \n",
    "            if anno == 'yes' or data[f'class{id_+1}'] !='N/A':\n",
    "                anno_corrected = 'yes'\n",
    "            else:\n",
    "                anno_corrected = 'no'\n",
    "            #anno_corrected = anno\n",
    "            \n",
    "            if meta == 'chatGPT_divergence':\n",
    "                divergence.append(anno_corrected)\n",
    "                divergence_type.append(data[f'class{id_+1}'])\n",
    "            if meta == 'chatGPT_paraphrase':\n",
    "                paraphrase.append(anno_corrected)\n",
    "            if meta == 'original':\n",
    "                #continue\n",
    "                original.append(anno_corrected)\n",
    "\n",
    "            #if meta == 'chatGPT_paraphrase' and anno=='yes':\n",
    "            #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/src_{ind}.txt', 'r') as src:\n",
    "            #        src = src.readlines()[0]\n",
    "            #        print(f'\\n{src}')\n",
    "\n",
    "            #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/tgt_{ind}.txt', 'r') as tgt:\n",
    "            #        tgt = tgt.readlines()[0]\n",
    "            #        print(f'\\n{tgt}')       \n",
    "    d_yes, d = divergence.count('yes'), len(divergence)\n",
    "    #print(f'Divergences: {d_yes} out of {d}')\n",
    "\n",
    "    p_no, p = paraphrase.count('no'), len(paraphrase)\n",
    "    #print(f'Paraphrase: {p_no} out of {p}')\n",
    "\n",
    "    o_no, o = original.count('no'), len(original)\n",
    "    #print(f'Paraphrase: {o_no} out of {o}')\n",
    "\n",
    "    tp = d_yes\n",
    "    fp = paraphrase.count('yes') + original.count('yes')\n",
    "    fn = divergence.count('no')\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    over_rel = paraphrase.count('yes') / len(paraphrase)\n",
    "    app_rel = (original.count('no') + divergence.count('yes'))/ (len(divergence) + len(original))\n",
    "    u = np.mean(usefuleness)\n",
    "    c = np.mean(conf)\n",
    "    a_[ data['with_hl']].append(precision)\n",
    "    #print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    #print(f'F1: {f1}')\n",
    "    #print(f'Ap-reliance: {app_rel}')\n",
    "    #print(f'Over-reliance: {over_rel}')\n",
    "    #print(f'Usefuleness: {u}')\n",
    "    #print(f'Self-confidence: {c}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c979aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6846221715447885\n",
      "0.7927933629227875\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_['true']) - np.std(a_['true']))\n",
    "print(np.mean(a_['false'])+ np.std(a_['false']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d598a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04931888739627042\n",
      "0.17718489731432185\n"
     ]
    }
   ],
   "source": [
    "print(np.std(a_['true']))\n",
    "print(np.std(a_['false']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0171d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "28.6057\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#np.mean(time_with)\n",
    "print(np.mean([float(a) for a in time_with]))\n",
    "print(np.std([float(a) for a in time_with]))\n",
    "print(np.mean([float(a) for a in time_without]))\n",
    "print(np.std([float(a) for a in time_without]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df09428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergences: 8 out of 8\n",
      "Paraphrase: 3 out of 5\n",
      "Paraphrase: 11 out of 12\n"
     ]
    }
   ],
   "source": [
    "d_yes, d = divergence.count('yes'), len(divergence)\n",
    "print(f'Divergences: {d_yes} out of {d}')\n",
    "\n",
    "p_no, p = paraphrase.count('no'), len(paraphrase)\n",
    "print(f'Paraphrase: {p_no} out of {p}')\n",
    "\n",
    "o_no, o = original.count('no'), len(original)\n",
    "print(f'Paraphrase: {o_no} out of {o}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f92f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7272727272727273\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tp = d_yes\n",
    "fp = paraphrase.count('yes') + original.count('yes')\n",
    "fn = divergence.count('no')\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb6c633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([float(a) for a in time_with])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7adcaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/ebriakou/opt/anaconda3/envs/playground/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([float(a) for a in time_with])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098d22eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.6057"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([float(a) for a in time_without])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35fa4c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([float(a) for a in time_without])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a72f063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n",
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n",
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n",
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n",
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_48.txt' mode='r' encoding='UTF-8'>\n",
      "48 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_2.txt' mode='r' encoding='UTF-8'>\n",
      "2 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_37.txt' mode='r' encoding='UTF-8'>\n",
      "37 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_8.txt' mode='r' encoding='UTF-8'>\n",
      "8 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_46.txt' mode='r' encoding='UTF-8'>\n",
      "46 chatGPT_paraphrase\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_39.txt' mode='r' encoding='UTF-8'>\n",
      "39 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_41.txt' mode='r' encoding='UTF-8'>\n",
      "41 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_17.txt' mode='r' encoding='UTF-8'>\n",
      "17 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_36.txt' mode='r' encoding='UTF-8'>\n",
      "36 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_43.txt' mode='r' encoding='UTF-8'>\n",
      "43 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_11.txt' mode='r' encoding='UTF-8'>\n",
      "11 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_12.txt' mode='r' encoding='UTF-8'>\n",
      "12 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_6.txt' mode='r' encoding='UTF-8'>\n",
      "6 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_35.txt' mode='r' encoding='UTF-8'>\n",
      "35 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_30.txt' mode='r' encoding='UTF-8'>\n",
      "30 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_40.txt' mode='r' encoding='UTF-8'>\n",
      "40 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_31.txt' mode='r' encoding='UTF-8'>\n",
      "31 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_28.txt' mode='r' encoding='UTF-8'>\n",
      "28 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_23.txt' mode='r' encoding='UTF-8'>\n",
      "23 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_14.txt' mode='r' encoding='UTF-8'>\n",
      "14 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_33.txt' mode='r' encoding='UTF-8'>\n",
      "33 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_32.txt' mode='r' encoding='UTF-8'>\n",
      "32 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_22.txt' mode='r' encoding='UTF-8'>\n",
      "22 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_5.txt' mode='r' encoding='UTF-8'>\n",
      "5 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_42.txt' mode='r' encoding='UTF-8'>\n",
      "42 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_45.txt' mode='r' encoding='UTF-8'>\n",
      "45 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_13.txt' mode='r' encoding='UTF-8'>\n",
      "13 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_49.txt' mode='r' encoding='UTF-8'>\n",
      "49 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_7.txt' mode='r' encoding='UTF-8'>\n",
      "7 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_4.txt' mode='r' encoding='UTF-8'>\n",
      "4 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_3.txt' mode='r' encoding='UTF-8'>\n",
      "3 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_47.txt' mode='r' encoding='UTF-8'>\n",
      "47 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_16.txt' mode='r' encoding='UTF-8'>\n",
      "16 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_38.txt' mode='r' encoding='UTF-8'>\n",
      "38 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_9.txt' mode='r' encoding='UTF-8'>\n",
      "9 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_1.txt' mode='r' encoding='UTF-8'>\n",
      "1 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_15.txt' mode='r' encoding='UTF-8'>\n",
      "15 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_19.txt' mode='r' encoding='UTF-8'>\n",
      "19 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_26.txt' mode='r' encoding='UTF-8'>\n",
      "26 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_27.txt' mode='r' encoding='UTF-8'>\n",
      "27 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_44.txt' mode='r' encoding='UTF-8'>\n",
      "44 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_18.txt' mode='r' encoding='UTF-8'>\n",
      "18 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_25.txt' mode='r' encoding='UTF-8'>\n",
      "25 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_24.txt' mode='r' encoding='UTF-8'>\n",
      "24 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_34.txt' mode='r' encoding='UTF-8'>\n",
      "34 chatGPT_divergence\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_29.txt' mode='r' encoding='UTF-8'>\n",
      "29 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_20.txt' mode='r' encoding='UTF-8'>\n",
      "20 original\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_21.txt' mode='r' encoding='UTF-8'>\n",
      "21 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_50.txt' mode='r' encoding='UTF-8'>\n",
      "50 chatGPT_paraphrase\n",
      "<_io.TextIOWrapper name='static/examples/for_user_study/flores_gpt_paraphrase_es/meta_lbl_10.txt' mode='r' encoding='UTF-8'>\n",
      "10 original\n",
      "Divergences: 99 out of 120\n",
      "Paraphrase: 30 out of 54\n",
      "Paraphrase: 97 out of 126\n",
      "Precision: 0.6513157894736842\n",
      "Recall: 0.825\n",
      "F1: 0.7279411764705881\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "lang ='es'\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "divergence, paraphrase, original = [], [],[]\n",
    "divergence_type = []\n",
    "time_without, time_with = [],[]\n",
    "with_, without_, gold_ = defaultdict(list), defaultdict(list),  defaultdict(str)\n",
    "with_type, without_type = defaultdict(list),  defaultdict(list)\n",
    "for f_name in glob(f'responses/{lang}/*.json'):\n",
    "    if f_name == f'responses/{lang}/marine.json':# or f_name == 'responses/fr/20230420-134831.json':\n",
    "        continue\n",
    "    #print(f_name)\n",
    "\n",
    "    f = open(f_name)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    #if data['with_hl'] == 'true':\n",
    "    #    continue\n",
    "    \n",
    "    #print(data['with_hl'])\n",
    "    #print(data['totalTimeInMinutes'])\n",
    "    if data['with_hl'] == 'true':\n",
    "        time_with.append(data['totalTimeInMinutes'])\n",
    "    else:\n",
    "        time_without.append(data['totalTimeInMinutes'])\n",
    "\n",
    "   \n",
    "    #try:\n",
    "    #    print(data['h28'])\n",
    "    #except:\n",
    "    #    continue\n",
    "\n",
    "    #divergence, paraphrase, original = [], [],[]\n",
    "    #divergence_type = []\n",
    "    inds = [a for a in data['sample_indices'].split(',')]\n",
    "    for id_, ind_ in enumerate(inds):\n",
    "        ind = str(ind_)\n",
    "        with open(f'static/examples/for_user_study/flores_gpt_paraphrase_{lang}/meta_lbl_{ind}.txt', 'r') as meta:\n",
    "            \n",
    "            print(meta)\n",
    "            meta = meta.readlines()[0]\n",
    "\n",
    "            try:\n",
    "                anno = data[f't{id_+1}']\n",
    "            except:\n",
    "                print('Missing')\n",
    "                continue\n",
    "\n",
    "            #print(f'\\nGold: {meta}')\n",
    "            #print(f'Anno: {anno}')\n",
    "            #if data['atncheck1'] != data['class2']:\n",
    "            #    print('Failed first attention check')\n",
    "\n",
    "            #if data['atncheck2'] != data['t7']:\n",
    "            #    print('Failed second attention check')\n",
    "                \n",
    "            if anno == 'yes' or data[f'class{id_+1}'] !='N/A':\n",
    "                anno_corrected = 'yes'\n",
    "            else:\n",
    "                anno_corrected = 'no'\n",
    "            #anno_corrected = anno\n",
    "            \n",
    "            if meta == 'chatGPT_divergence':\n",
    "                divergence.append(anno_corrected)\n",
    "                divergence_type.append(data[f'class{id_+1}'])\n",
    "            if meta == 'chatGPT_paraphrase':\n",
    "                paraphrase.append(anno_corrected)\n",
    "            if meta == 'original':\n",
    "                #continue\n",
    "                original.append(anno_corrected)\n",
    "\n",
    "            if data['with_hl'] == 'true':\n",
    "                with_[ind].append(anno_corrected)\n",
    "                with_type[ind].append(data[f'class{id_+1}'])\n",
    "            else:\n",
    "                without_[ind].append(anno_corrected)\n",
    "                without_type[ind].append(data[f'class{id_+1}'])\n",
    "\n",
    "            \n",
    "            print(f'{ind} {meta}')\n",
    "            gold_[ind] = meta\n",
    "                \n",
    "            #if meta == 'chatGPT_paraphrase' and anno=='yes':\n",
    "            #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/src_{ind}.txt', 'r') as src:\n",
    "            #        src = src.readlines()[0]\n",
    "            #        print(f'\\n{src}')\n",
    "\n",
    "            #    with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/tgt_{ind}.txt', 'r') as tgt:\n",
    "            #        tgt = tgt.readlines()[0]\n",
    "            #        print(f'\\n{tgt}')       \n",
    "d_yes, d = divergence.count('yes'), len(divergence)\n",
    "print(f'Divergences: {d_yes} out of {d}')\n",
    "\n",
    "p_no, p = paraphrase.count('no'), len(paraphrase)\n",
    "print(f'Paraphrase: {p_no} out of {p}')\n",
    "\n",
    "o_no, o = original.count('no'), len(original)\n",
    "print(f'Paraphrase: {o_no} out of {o}')\n",
    "        \n",
    "tp = d_yes\n",
    "fp = paraphrase.count('yes') + original.count('yes')\n",
    "fn = divergence.count('no')\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d0c95ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['chatGPT_paraphrase', 'chatGPT_divergence', 'original', 'chatGPT_paraphrase', 'original', 'chatGPT_divergence', 'original', 'chatGPT_paraphrase', 'chatGPT_divergence', 'chatGPT_paraphrase', 'original', 'original', 'original', 'original', 'chatGPT_divergence', 'chatGPT_divergence', 'chatGPT_divergence', 'original', 'chatGPT_divergence', 'original', 'original', 'original', 'chatGPT_divergence', 'chatGPT_divergence', 'chatGPT_divergence', 'chatGPT_paraphrase', 'chatGPT_divergence', 'original', 'original', 'original', 'chatGPT_divergence', 'chatGPT_divergence', 'original', 'chatGPT_divergence', 'original', 'chatGPT_paraphrase', 'chatGPT_divergence', 'chatGPT_paraphrase', 'chatGPT_divergence', 'chatGPT_divergence', 'original', 'chatGPT_paraphrase', 'chatGPT_divergence', 'chatGPT_divergence', 'original', 'chatGPT_divergence', 'chatGPT_paraphrase', 'original', 'original', 'original'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d51dc9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5168635240055396\n",
      "0.06521236940740419\n",
      "0.2867320785653002\n",
      "0.09119029053576083\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "k = []\n",
    "for i in range(50):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in with_.values():\n",
    "        [l1, l2] = random.sample(annos, 2)\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "\n",
    "k = []\n",
    "for i in range(50):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in without_.values():\n",
    "        [l1, l2] = random.sample(annos, 2)\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b88c7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.782608695652174\n",
      "Recall: 0.9\n",
      "F1: 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "tp, fn, fp = 0, 0, 0\n",
    "for key, value in with_.items():\n",
    "    \n",
    "    if gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    \n",
    "    elif gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "        \n",
    "    elif gold_[key] != 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "        \n",
    "    #print(gold_[key])\n",
    "    #print(most_frequent(value))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52076105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "with_flattened = defaultdict(str)\n",
    "for key, value in with_.items():\n",
    "    with_flattened[f'{key}_a'] = value[0]\n",
    "    with_flattened[f'{key}_b'] = value[1]\n",
    "    try:\n",
    "        with_flattened[f'{key}_c'] = value[2]\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "without_flattened = defaultdict(str)\n",
    "for key, value in without_.items():\n",
    "    without_flattened[f'{key}_a'] = value[0]\n",
    "    without_flattened[f'{key}_b'] = value[1]\n",
    "    try:\n",
    "        without_flattened[f'{key}_c'] = value[2]\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(len(with_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b9ce18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0242\n",
      "0.1107\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pr_with_, re_with_, f1_with_ = [], [],[]\n",
    "pr_without_, re_without_, f1_without_ = [], [],[]\n",
    "\n",
    "samples = 10000\n",
    "subsample_size = 149\n",
    "p_pr, p_re, p_f1 = 0, 0, 0\n",
    "for i in range(samples):\n",
    "\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    subsample = []\n",
    "    for j in range(subsample_size):\n",
    "        subsample.append(random.sample(list(with_flattened.keys()), 1)[0])\n",
    "    \n",
    "    #subsample = random.sample(list(with_flattened.keys()), subsample_size)\n",
    "    \n",
    "    for key in subsample:\n",
    "\n",
    "        sampled = with_flattened[key]\n",
    "        if gold_[key.split('_')[0]] == 'chatGPT_divergence' and sampled == 'yes':\n",
    "            tp +=1\n",
    "\n",
    "        elif gold_[key.split('_')[0]] == 'chatGPT_divergence' and sampled == 'no':\n",
    "            fn +=1\n",
    "\n",
    "        elif gold_[key.split('_')[0]] != 'chatGPT_divergence' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_with = tp/(tp+fp)\n",
    "    recall_with = tp/(tp+fn)\n",
    "    f1_with = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "\n",
    "    pr_with_.append(precision_with)\n",
    "    re_with_.append(recall_with)\n",
    "    f1_with_.append(f1_with)\n",
    "    \n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    subsample = []\n",
    "    for j in range(subsample_size):\n",
    "        subsample.append(random.sample(list(without_flattened.keys()), 1)[0])\n",
    "    \n",
    "    #subsample = random.sample(list(with_flattened.keys()), subsample_size)\n",
    "    \n",
    "    for key in subsample:\n",
    "\n",
    "        sampled = without_flattened[key]\n",
    "        if gold_[key.split('_')[0]] == 'chatGPT_divergence' and sampled == 'yes':\n",
    "            tp +=1\n",
    "\n",
    "        elif gold_[key.split('_')[0]] == 'chatGPT_divergence' and sampled == 'no':\n",
    "            fn +=1\n",
    "\n",
    "        elif gold_[key.split('_')[0]] != 'chatGPT_divergence' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_without = tp/(tp+fp)\n",
    "    recall_without = tp/(tp+fn)\n",
    "    f1_without = 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    if recall_with < recall_without:\n",
    "        p_re+=1\n",
    "    if precision_with < precision_without:\n",
    "        p_pr+=1\n",
    "    if f1_with < f1_without:\n",
    "        print('a')\n",
    "        p_f1+=1\n",
    "    pr_without_.append(precision_without)\n",
    "    re_without_.append(recall_without)\n",
    "    f1_without_.append(f1_without)\n",
    "    \n",
    "print(p_pr/samples)\n",
    "print(p_re/samples)\n",
    "print(p_f1/samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f56ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043\n",
      "0.085\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pr_with_, re_with_, f1_with_ = [], [],[]\n",
    "pr_without_, re_without_, f1_without_ = [], [],[]\n",
    "\n",
    "samples = 5000\n",
    "p_pr, p_re, p_f1 = 0, 0, 0\n",
    "for i in range(samples):\n",
    "\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    \n",
    "    for key, value in with_.items():\n",
    "\n",
    "        sampled = random.sample(value, 1)[0]\n",
    "        if gold_[key] == 'chatGPT_divergence' and sampled == 'yes':\n",
    "            tp +=1\n",
    "\n",
    "        elif gold_[key] == 'chatGPT_divergence' and sampled == 'no':\n",
    "            fn +=1\n",
    "\n",
    "        elif gold_[key] != 'chatGPT_divergence' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_with = tp/(tp+fp)\n",
    "    recall_with = tp/(tp+fn)\n",
    "    f1_with = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    pr_with_.append(precision_with)\n",
    "    re_with_.append(recall_with)\n",
    "    f1_with_.append(f1_with)\n",
    "    \n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for key, value in without_.items():\n",
    "\n",
    "        sampled = random.sample(value, 1)[0]\n",
    "        if gold_[key] == 'chatGPT_divergence' and sampled == 'yes':\n",
    "            tp +=1\n",
    "\n",
    "        elif gold_[key] == 'chatGPT_divergence' and sampled == 'no':\n",
    "            fn +=1\n",
    "\n",
    "        elif gold_[key] != 'chatGPT_divergence' and sampled == 'yes':\n",
    "            fp +=1\n",
    "\n",
    "        #print(gold_[key])\n",
    "        #print(most_frequent(value))\n",
    "    precision_without = tp/(tp+fp)\n",
    "    recall_without = tp/(tp+fn)\n",
    "    f1_without = 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    if recall_with < recall_without:\n",
    "        p_re+=1\n",
    "    if precision_with < precision_without:\n",
    "        p_pr+=1\n",
    "    if f1_with < f1_without:\n",
    "        print('a')\n",
    "        p_f1+=1\n",
    "    pr_without_.append(precision_without)\n",
    "    re_without_.append(recall_without)\n",
    "    f1_without_.append(f1_without)\n",
    "    \n",
    "print(p_pr/samples)\n",
    "print(p_re/samples)\n",
    "print(p_f1/samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d624e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d943b5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78375\n",
      "0.06274103521619644\n",
      "0.6836548961451192\n",
      "0.050004506600243234\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(re_without_))\n",
    "print(np.std(re_without_))\n",
    "\n",
    "print(np.mean(pr_without_))\n",
    "print(np.std(pr_without_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad629ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86674\n",
      "0.047135680752483027\n",
      "0.8022101159063711\n",
      "0.053624840834120106\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(re_with_))\n",
    "print(np.std(re_with_))\n",
    "\n",
    "print(np.mean(pr_with_))\n",
    "print(np.std(pr_with_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6b12f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6956521739130435\n",
      "Recall: 0.8\n",
      "F1: 0.7441860465116279\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp = 0, 0, 0\n",
    "for key, value in without_.items():\n",
    "    \n",
    "    if gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    \n",
    "    elif gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "        \n",
    "    elif gold_[key] != 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "        \n",
    "    #print(gold_[key])\n",
    "    #print(most_frequent(value))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d32460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8181818181818182\n",
      "Recall: 0.9\n",
      "F1: 0.8571428571428572\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp = 0, 0, 0\n",
    "for key, value in with_.items():\n",
    "    \n",
    "    if gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        tp +=1\n",
    "    \n",
    "    elif gold_[key] == 'chatGPT_divergence' and most_frequent(value) == 'no':\n",
    "        fn +=1\n",
    "        \n",
    "    elif gold_[key] != 'chatGPT_divergence' and most_frequent(value) == 'yes':\n",
    "        fp +=1\n",
    "        \n",
    "    #print(gold_[key])\n",
    "    #print(most_frequent(value))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365f0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45128643241765043\n",
      "0.07499825937541749\n",
      "0.42801226228823147\n",
      "0.06269445866049854\n",
      "fr\n"
     ]
    }
   ],
   "source": [
    "k = []\n",
    "for i in range(100):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in with_type.values():\n",
    "        #if len(set(annos))==1 and annos[0]=='N/A':\n",
    "        #    continue\n",
    "        #annos = [a for a in annos if a!='N/A']\n",
    "        try:\n",
    "            [l1, l2] = random.sample(annos, 2)\n",
    "        except:\n",
    "            continue\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "\n",
    "k = []\n",
    "for i in range(100):\n",
    "    labeler1, labeler2 = [],[]\n",
    "\n",
    "    for annos in without_type.values():\n",
    "        #if len(set(annos))==1 and annos[0]=='N/A':\n",
    "        #    continue\n",
    "        #annos = [a for a in annos if a!='N/A']\n",
    "        try:\n",
    "            [l1, l2] = random.sample(annos, 2)\n",
    "        except:\n",
    "            continue\n",
    "        labeler1.append(l1)\n",
    "        labeler2.append(l2)\n",
    "    k.append(cohen_kappa_score(labeler1, labeler2))\n",
    "    \n",
    "print(np.mean(k))\n",
    "print(np.std(k))\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8bb9f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "['N/A', 'N/A', 'N/A']\n",
      "['N/A', 'N/A', 'N/A']\n",
      "\n",
      " Caretaker Prime Minister Julia Gillard claimed during the campaign of the 2010 <h-l-1>state</h-l-1> election that she believed Australia should become a republic at the end of Queen Elizabeth II's reign.\n",
      "\n",
      " La première ministre intérimaire Julia Gillard a déclaré pendant la campagne des élections <h-l-1>fédérales</h-l-1> de 2010 qu'elle pensait que l'Australie devrait devenir une république à la fin du règne de la reine Elizabeth II.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['N/A', 'N/A', 'Added (in French)']\n",
      "['Changed', 'N/A', 'Changed']\n",
      "\n",
      " The High Middle Ages <h-l-1>were</h-l-1> preceded by the Early Middle Ages and followed by the Late Middle Ages, which strictly speaking ends around 1500.\n",
      "\n",
      " Le Moyen Âge <h-l-1>Central a été</h-l-1> précédé par le Haut Moyen Âge et suivi par le Bas Moyen Âge, qui par convention se termine vers 1500.\n"
     ]
    }
   ],
   "source": [
    "for key, value in with_.items():\n",
    "    #if most_frequent(value) != most_frequent(without_[key]):\n",
    "    if True:\n",
    "        #print('\\n')\n",
    "        #print(value)\n",
    "        if gold_[key] == 'chatGPT_divergence' and most_frequent(value) =='no':# and most_frequent(without_[key]) == 'no':\n",
    "            print('-'*100)\n",
    "            #print(key)\n",
    "            print(with_type[key])\n",
    "            print(without_type[key])\n",
    "            #print(gold_[key])\n",
    "            with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/src_{key}.txt', 'r') as src:\n",
    "                src = src.readlines()[0]\n",
    "                print(f'\\n{src}')\n",
    "\n",
    "            with open(f'static/examples/for_user_study/flores_gpt_paraphrase_fr/tgt_{key}.txt', 'r') as tgt:\n",
    "                tgt = tgt.readlines()[0]\n",
    "                print(f'\\n{tgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78534ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gold_.values()).count('chatGPT_divergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32efc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for key, value in with_type.items():\n",
    "    t.extend([a for a in value if a!='N/A' and a!='Other'])\n",
    "j = []\n",
    "for key, value in without_type.items():\n",
    "    j.extend([a for a in value if a!='N/A'  and a!='Other'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "377dbd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212a83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR3klEQVR4nO3debBkZX3G8e/DJipYQrg1QWQcd0NEUa9GQQ24RY2WS6GEWAajZkiMW6IkahJDlqpoxS1qXEakQEVEBUoRE0UFjULQgUIYQEOiIODIjIlxq6gZ/OWPcyY2d+7Sd+ae7pl5v5+qrnv6Pcv76z59n3v67dPnpqqQJLVjj2kXIEmaLINfkhpj8EtSYwx+SWqMwS9Jjdlr2gWM46CDDqo1a9ZMuwxJ2qVcdtll362qmbntu0Twr1mzhvXr10+7DEnapSS5Yb52h3okqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4Jakxu8Q3d3fEIYeu5ts33TjtMjTHXe56KDff+K1plyE1abcP/m/fdCPHvfviaZehOc468chplyA1y6EeSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0ZLPiTHJrkwiTXJLk6ycv69pOT3Jzkiv725KFqkCRta8hr9WwBXlFVlyfZH7gsyQX9vDdX1RsG7FuStIDBgr+qNgIb++kfJrkWOGSo/iRJ45nIGH+SNcCDgEv7phcnuTLJqUkOWGCdtUnWJ1m/efPmSZQpSU0YPPiT7AecDby8qn4AvBO4J3AE3TuCN863XlWtq6rZqpqdmZkZukxJasagwZ9kb7rQP6OqzgGoqluq6taq+jnwHuBhQ9YgSbqtIc/qCfBe4NqqetNI+8Ejiz0D2DBUDZKkbQ15Vs9RwHOBq5Jc0be9Bjg+yRFAAdcDJw5YgyRpjiHP6vkikHlmfXKoPiVJS/Obu5LUGINfkhoz5Bi/pF3IIYeu5ts33TjtMjTHXe56KDff+K0V3abBLwmAb990I8e9++Jpl6E5zjrxyBXfpkM9ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSYwYI/yaFJLkxyTZKrk7ysbz8wyQVJrut/HjBUDZKkbQ15xL8FeEVVHQY8HPjDJIcBrwI+W1X3Bj7b35ckTchgwV9VG6vq8n76h8C1wCHA04DT+8VOB54+VA2SpG1NZIw/yRrgQcClwKqq2tjP+g6waoF11iZZn2T95s2bJ1GmJDVh8OBPsh9wNvDyqvrB6LyqKqDmW6+q1lXVbFXNzszMDF2mJDVj0OBPsjdd6J9RVef0zbckObiffzCwacgaJEm3NeRZPQHeC1xbVW8amfVx4IR++gTgY0PVIEna1l4Dbvso4LnAVUmu6NteA7wO+HCSFwA3AM8esAZJ0hyDBX9VfRHIArMfO1S/kqTF+c1dSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxYwV/kqPGaZMk7fzGPeJ/25htkqSd3F6LzUzyCOBIYCbJH4/MuhOw55CFSZKGsdQR/z7AfnR/IPYfuf0AOHaxFZOcmmRTkg0jbScnuTnJFf3tyTtWviRpuRY94q+qzwOfT3JaVd2wzG2fBrwdeN+c9jdX1RuWuS1J0gpZNPhH3C7JOmDN6DpV9ZiFVqiqLyRZs0PVSZJW3LjB/xHgXcApwK072OeLk/wOsB54RVV9b76FkqwF1gKsXr16B7vUTmePvUgy7SqkJo0b/Fuq6p0r0N87gb8Bqv/5RuD58y1YVeuAdQCzs7O1An1rZ/LzLRz37ounXYVGnHXikdMuQRMy7umc5yV5UZKDkxy49bbczqrqlqq6tap+DrwHeNhytyFJ2jHjHvGf0P88aaStgHssp7MkB1fVxv7uM4ANiy0vSVp5YwV/Vd19uRtOciZwNHBQkpuAvwSOTnIE3R+N64ETl7tdSdKOGSv4+w9jt1FVc0/VHJ13/DzN7x2zLknSQMYd6nnoyPS+wGOBy9n2HH1J0k5u3KGel4zeT3Jn4ENDFCRJGtb2Xpb5x8Cyx/0lSdM37hj/eXQfyEJ3cbZfAT48VFGSpOGMO8Y/em2dLcANVXXTAPVIkgY21lBPf7G2r9FdmfMA4GdDFiVJGs64/4Hr2cCXgWcBzwYuTbLoZZklSTuncYd6/gx4aFVtAkgyA3wG+OhQhUmShjHuWT17bA393n8uY11J0k5k3CP+f07yKeDM/v5xwCeHKUmSNKSl/ufuvYBVVXVSkmcCj+xnXQKcMXRxkqSVt9QR/1uAVwNU1TnAOQBJDu/nPXXA2iRJA1hqnH5VVV01t7FvWzNIRZKkQS0V/HdeZN7tV7AOSdKELBX865P83tzGJC8ELhumJEnSkJYa4385cG6S5/CLoJ8F9qH7D1qSpF3MosFfVbcARyY5Brh/33x+VX1u8MokSYMY93r8FwIXDlyLJGkC/PatJDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmMGCP8mpSTYl2TDSdmCSC5Jc1/88YKj+JUnzG/KI/zTgiXPaXgV8tqruDXy2vy9JmqDBgr+qvgD815zmpwGn99OnA08fqn9J0vwmPca/qqo29tPfAVYttGCStUnWJ1m/efPmyVQnSQ2Y2oe7VVVALTJ/XVXNVtXszMzMBCuTpN3bpIP/liQHA/Q/N024f0lq3qSD/+PACf30CcDHJty/JDVvyNM5zwQuAe6b5KYkLwBeBzw+yXXA4/r7kqQJGut/7m6Pqjp+gVmPHapPSdLS/OauJDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1Jj9ppGp0muB34I3ApsqarZadQhSS2aSvD3jqmq706xf0lqkkM9ktSYaQV/AZ9OclmStfMtkGRtkvVJ1m/evHnC5UnS7mtawf/Iqnow8CTgD5M8eu4CVbWuqmaranZmZmbyFUrSbmoqwV9VN/c/NwHnAg+bRh2S1KKJB3+SOybZf+s08ARgw6TrkKRWTeOsnlXAuUm29v/BqvrnKdQhSU2aePBX1TeAB066X0lSx9M5JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmOmEvxJnpjk60n+PcmrplGDJLVq4sGfZE/gH4EnAYcBxyc5bNJ1SFKrpnHE/zDg36vqG1X1M+BDwNOmUIckNSlVNdkOk2OBJ1bVC/v7zwV+rapePGe5tcDa/u59ga9PtNCd00HAd6ddhG7DfbJzcr907lZVM3Mb95pGJeOoqnXAumnXsTNJsr6qZqddh37BfbJzcr8sbhpDPTcDh47cv2vfJkmagGkE/1eAeye5e5J9gN8CPj6FOiSpSRMf6qmqLUleDHwK2BM4taqunnQduyiHvnY+7pOdk/tlERP/cFeSNF1+c1eSGmPwS1JjDP6BJPnlJB9K8h9JLkvyySRrk3xi2rUBJDl6Z6llriRPT1JJ7rfIMhcl2eZ0vSTPS/L2ZfZ3fZKD5mlPks8luVN//+Jlbve0JN9MckV/W9b682zr2H76lMW+7b7Ic3N4ktO2t4Z+G7vrvnnpctZfZl8LPYanJPnrofpdjME/gCQBzgUuqqp7VtVDgFcDq6Zb2S7jeOCL/c9pejLw1ar6AUBVHbkd2zipqo7ob9uz/jaq6oVVdc12rHcVcNckq3eg+91137x1dEaSSZz4cj7w1CR3mEBft2HwD+MY4H+r6l1bG6rqq8C/APsl+WiSryU5o/8jQZLXJvlKkg1J1o20X5Tk9Um+nOTfkjyqb79Dkg8nuSbJuUku3XqUleQJSS5JcnmSjyTZr29/Yt/v5cAzJ/uUjKev9ZHAC+hO9d3afvv+HdS1Sc4Fbj8y73f75+bLwFEj7TNJzu6f168kOapv/6Ukn05ydZJTgCxQznOAj41s70f9z6P7/bLNfhzzMZ6c5NR+G98YPdpM8hfpLmD4xSRnJnnlPOtflGQ2yZ79keuGJFcl+aORxZ419zXTO4+R53U5dvd906/3liTrgZcleUiSz6d7x/6pJAePLDff7+SeSd7Q748rk7xkZPMv6X8fr0r/bqm6M2suAp4yTn0rqqq8rfANeCnw5nnajwa+T/eltT2AS4BH9vMOHFnu/cBT++mLgDf2008GPtNPvxJ4dz99f2ALMEv3VfUvAHfs5/0p8FpgX+BG4N50v0wfBj4x7edqnufoOcB7++mLgYf0039Md+ovwANGHu/BwLeAGWAf4EvA2/vlPjjy/K4Gru2n3wq8tp/+TaCAg+ap5QZg/5H7P1pqP85Z/zTgm8AV/e2Mvv3k/rHdrt9f/wnsDTy0X25fYH/gOuCVI9s6duQ1MQs8BLhgpL87L/aa6e8fBZznvtlm3xzeP2/v6Ofv3T/Gmf7+cSOPcd7nF/gD4KPAXqO/08D1wEv66RcBp8x5Tt826d+znfaSDbuxL1fVTQBJrgDW0L11PibJnwB3AA4ErqY7OgM4p/95Wb88dEde/wBQVRuSXNm3P5zuqqdf6g909qF78d8P+GZVXdf3/QF+cS2kncnx9I+L7gJ+x9M97kfThQJVdeXI4/01uiG1zQBJzgLu0897HHDYyAHfnfqj1kfTv+OpqvOTfG+BWg6sqh8uMG+h/TjXSVX10Xnaz6+qnwI/TbKJbhjwKOBjVfUT4CdJzptnvVHfAO6R5G10wwafHpk332sGYBNwlyW2u5Ddet/0tZzV370v3QHVBX37nsDGkXXne34fB7yrqrb09f/XAsuPvtvekf2x3Qz+YVwNHLvAvJ+OTN8K7JVkX+AdwGxV3ZjkZLqjvrnr3MrS+yx0R4G3GYNNcsR4pU9PkgOBxwCHJym6X7ZKctJ2bnIP4OF9kI72M+76W5LsUVU/n2feNvtxmbXt6PpU1feSPBD4DeD3gWcDz5+z/bnb3hf4n+X21dC++fHWUoCrq+oRCyy3nN/JxZbfrv2xoxzjH8bngNulu8IoAEkeADxqgeW3hvx3+6Oehf5ojPoS3S866c7wOLxv/1fgqCT36ufdMcl9gK8Ba5Lcs19u2h/OzedY4P1VdbeqWlNVh9K9HX8U3fDVbwMkuT/dkALApcCv92PDewPPGtnep4H/H2cd+eM3uq0nAQcsUM/XgXuswOMa15foPuzbt38dLDr2m+5MkT2q6mzgz4EHj9HHfYAN21Fba/vm68BMkkf0teyd5FeXWOcC4MT0Hwz3fyyXsr37Y4cY/AOobvDuGcDj0p3OeTXwd8B3Flj+v4H30L0APkV3PaOlvIPuhXkN8Ld07zK+37+tfh5wZv+W+xLgfv2R1Vrg/HQf7m7a/kc4mOPpzoYadXbf/k66D8avBf6a7i0zVbWRbsz8ErrgvHZk3ZcCs/0HbdfQHRUD/BXw6H6/PJNuHHo+59ONGe+Iv88vThm8It31qeZVVV+hu27VlcA/AVfRjVcv5BDgon444wN0Z44t5Ri6x7Vcu+O+WVB1/yvkWOD1Sb5K9znAUmcOnUJX75X9Or89Rlfbuz92iJds2EWl+09me1fVT/qj+M8A9+1fsFoB/Vkc76uqx0+wz/2q6kfpTvH7ArC2qi5foW3fDvg83YedW1Zim9MyjX2z0pKsAj5YVY+ddN+O8e+67gBc2L+FDvAiQ39lVdXGJO9JcqfqzxefgHX90N2+wOkrFfq91cCrdvXQh6ntm5W2GnjFNDr2iF+SGuMYvyQ1xuCXpMYY/JLUGINfkhpj8EtSY/4Pu5p5gcWlPw8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46bb08b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'36': ['no', 'no', 'no'],\n",
       "             '21': ['no', 'yes', 'no'],\n",
       "             '16': ['no', 'no', 'no'],\n",
       "             '27': ['no', 'no', 'no'],\n",
       "             '22': ['no', 'no', 'no'],\n",
       "             '11': ['yes', 'yes', 'yes'],\n",
       "             '3': ['yes', 'yes', 'yes'],\n",
       "             '24': ['yes', 'yes', 'no'],\n",
       "             '46': ['no', 'no', 'no'],\n",
       "             '44': ['yes', 'no', 'yes'],\n",
       "             '49': ['yes', 'yes', 'yes'],\n",
       "             '8': ['no', 'no', 'yes'],\n",
       "             '25': ['no', 'no', 'no'],\n",
       "             '19': ['yes', 'yes', 'yes'],\n",
       "             '30': ['no', 'no', 'no'],\n",
       "             '45': ['yes', 'yes', 'yes'],\n",
       "             '34': ['no', 'no', 'no'],\n",
       "             '43': ['yes', 'yes', 'yes'],\n",
       "             '48': ['yes', 'yes', 'yes'],\n",
       "             '5': ['yes', 'yes', 'yes'],\n",
       "             '7': ['no', 'no', 'no'],\n",
       "             '23': ['yes', 'yes', 'yes'],\n",
       "             '20': ['no', 'yes', 'no'],\n",
       "             '28': ['no', 'no', 'no'],\n",
       "             '14': ['no', 'yes', 'no'],\n",
       "             '6': ['yes', 'yes', 'yes'],\n",
       "             '4': ['yes', 'no', 'no'],\n",
       "             '41': ['no', 'yes', 'no'],\n",
       "             '50': ['yes', 'yes', 'yes'],\n",
       "             '12': ['yes', 'yes', 'no'],\n",
       "             '35': ['yes', 'yes', 'yes'],\n",
       "             '40': ['no', 'no', 'no'],\n",
       "             '17': ['yes', 'no', 'no'],\n",
       "             '10': ['no', 'no', 'no'],\n",
       "             '38': ['yes', 'yes', 'yes'],\n",
       "             '31': ['yes', 'no', 'yes'],\n",
       "             '18': ['no', 'yes', 'no'],\n",
       "             '9': ['no', 'no', 'no'],\n",
       "             '39': ['no', 'no', 'no'],\n",
       "             '42': ['yes', 'no', 'yes'],\n",
       "             '13': ['no', 'no', 'no'],\n",
       "             '37': ['no', 'no', 'no'],\n",
       "             '1': ['no', 'no', 'no'],\n",
       "             '33': ['no', 'no', 'no'],\n",
       "             '2': ['yes', 'yes', 'no'],\n",
       "             '47': ['yes', 'yes', 'no'],\n",
       "             '32': ['yes', 'yes', 'no'],\n",
       "             '29': ['yes', 'no', 'yes'],\n",
       "             '15': ['no', 'yes', 'no'],\n",
       "             '26': ['yes', 'yes', 'yes']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1742c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32d532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
